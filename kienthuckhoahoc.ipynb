{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://kienthuckhoahoc.org/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = list()\n",
    "\n",
    "res = requests.get(url)\n",
    "soup = bs(res.content)\n",
    "title_div = soup.find('div', class_ = 'navbox clearfix')\n",
    "titles = title_div.find_all('li')\n",
    "\n",
    "for element in titles:\n",
    "  title = element.find('a')\n",
    "  topics.append(title['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/khao-co', '/video', '/anh-dep', '/dai-duong-hoc', '/su-kien-kh', '/9999-bi-an', '/cau-chuyen-khoa-hoc', '/cong-trinh-khoa-hoc', '/thu-gian', '/di-san', '/lich-su', '/kh-va-ban-doc', '/suc-khoe-y-hoc', '/suc-khoe-y-hoc/suc-khoe', '/cong-nghe/cong-nghe-moi', '/moi-truong', '/moi-truong/tham-hoa', '/sinh-vat/con-trung-vi-khuan', '/sinh-vat/thuc-vat', '/ung-dung-kh', '/moi-truong/thoi-tiet', '/moi-truong/giai-phap', '/moi-truong/thien-nhien', '/suc-khoe-y-hoc/dich-cum', '/cong-nghe/kh-may-tinh', '/sinh-vat/cong-nghe-sinh-hoc', '/suc-khoe-y-hoc/ung-thu', '/moi-truong/tin-bao', '/cong-nghe/phat-minh-kh', '/suc-khoe-y-hoc/thuc-pham', '/di-san/van-hoa', '/lich-su/ngay-nam-xua', '/di-san/thien-nhien', '/cong-nghe/phan-mem-hay', '/di-san/phi-vat-the', '/di-san/hon-hop', '/di-san/tu-lieu']\n"
     ]
    }
   ],
   "source": [
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(url):\n",
    "    article_name = list()\n",
    "    res = requests.get(url)\n",
    "    soup = bs(res.content)\n",
    "    articles = soup.find('div', class_ = \"listview\")\n",
    "    if articles:\n",
    "        li_elements = articles.find_all('li')\n",
    "        for article in li_elements:\n",
    "            if article.find('a'):\n",
    "                article_name.append(article.find('a')['href'])\n",
    "    return article_name        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_article = dict()   #key: topic - value: list of articles's link\n",
    "\n",
    "for topic in topics:\n",
    "    topic_article[topic] = list()\n",
    "    for page in range(2, 150):\n",
    "        link = f\"{url}{topic}/page{page}\"\n",
    "        article_name = get_article(link)\n",
    "        topic_article[topic].extend(article_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2220"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_article['/suc-khoe-y-hoc/suc-khoe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(link):\n",
    "    paragraph = \"\"\n",
    "    res = requests.get(link)\n",
    "    soup = bs(res.content)\n",
    "    contents = soup.find('div', class_ = \"content-detail\")\n",
    "    if contents:\n",
    "        contents = contents.find_all('p')\n",
    "        for content in contents:\n",
    "            if \"Nguồn bài viết: \" in str(content):\n",
    "                break\n",
    "            if 'div class=' not in str(content):\n",
    "                paragraph += str(content)\n",
    "    return paragraph\n",
    "\n",
    "import os\n",
    "def save(path, paragraph, index):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    path += f\"/{index}.txt\"\n",
    "    with open(path, \"w\") as file:\n",
    "        file.write(paragraph)\n",
    "\n",
    "for topic in topic_article.keys():\n",
    "    for index, article in enumerate(topic_article[topic]):\n",
    "        link = f\"{url}{article}\"\n",
    "        paragraph = crawl(link)\n",
    "        path = f\"data/{topic}\"\n",
    "        save(path, paragraph, index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selenium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fcfe45a30d11f3d7eb0e868e93429f3229ab1ba6cb4750704a358d49709c955"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
